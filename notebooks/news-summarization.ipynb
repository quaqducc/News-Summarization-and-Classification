{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121  # (nếu có GPU CUDA 12.1)\n!pip install transformers datasets evaluate nltk\n!pip install sentencepiece  # cần cho tokenizer BART/T5\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 0. Import libraries","metadata":{}},{"cell_type":"code","source":"import nltk\nimport numpy as np\nfrom datasets import load_dataset\nimport evaluate\nfrom transformers import (\n    BartForConditionalGeneration,\n    BartTokenizerFast,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    DataCollatorForSeq2Seq\n)\n\nnltk.download(\"punkt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Load dataset","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Load tokenizer & model","metadata":{}},{"cell_type":"code","source":"model_name = \"facebook/bart-large-cnn\"\ntokenizer = BartTokenizerFast.from_pretrained(model_name)\nmodel = BartForConditionalGeneration.from_pretrained(model_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  3. Preprocess function","metadata":{}},{"cell_type":"code","source":"max_input_length = 512\nmax_target_length = 128\n\ndef preprocess_function(examples):\n    inputs = [doc for doc in examples[\"article\"]]\n    targets = [tgt for tgt in examples[\"highlights\"]]\n    model_inputs = tokenizer(\n        inputs, max_length=max_input_length, truncation=True, padding=\"max_length\"\n    )\n    labels = tokenizer(\n        targets, max_length=max_target_length, truncation=True, padding=\"max_length\"\n    )\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_datasets = dataset.map(\n    preprocess_function, \n    batched=True, \n    remove_columns=[\"article\", \"highlights\", \"id\"]\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Data collator & metrics","metadata":{}},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\nrouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Tính ROUGE\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {key: round(value * 100, 2) for key, value in result.items()}\n    return result\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Training config","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade transformers accelerate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./models/bart_summarizer\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=15,  \n    predict_with_generate=True,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_strategy=\"epoch\",\n    fp16=True,\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],  \n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Train","metadata":{}},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"2239cd9d93e77db267b258d6da608bf2a7e5a516\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(\"./models/bart_summarizer\")\ntokenizer.save_pretrained(\"./models/bart_summarizer\")\n\n# chạy evaluate sau training\nresults = trainer.evaluate()\nprint(\"ROUGE scores:\", results)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}